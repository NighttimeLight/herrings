---
title: "Herrings"
output: 
  html_document:
    toc: true
    theme: lumen
date: "`r Sys.Date()`"
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r libraries, warning=F, message=F}
library(dplyr)
library(tidyr)
library(caret)
library(ggplot2)
library(corrplot)
library(gganimate)
library(knitr)
#library(plotly)
#library(shiny)
#library(flexdashboard)
#library(ggsci)
```

```{r setup_late}
set.seed(5)
theme_set(theme_classic())
```

# Summary

Source data contained not many NA values. Based on initial processing years were assumed from `totaln` and position in source. Records were aggregated to the level of separate months each value being the mean of aggregated rows.

Such data showed noticeable linear correlation across groups of catch measures (`fbar`, `recr`,`cumf`, `totaln`) and plankton amount (`cfin1`, `cfin2`, `chel1`, `chel2`,`clop1`, `clop2`) and between `length`, `sst` and time.

Constructed regression model showed that the most significant for the `length` of herrings were

* local catch intensity
* total number of herrings catched
* sea surface temperature

Based on the distribution of these measures, it can be concluded that crucial influence on decrease in herrings length over last years had increase in sea surface temperature.


# Load data

```{r load_herrings, cache=T}
df_sample <- read.csv("sledzie.csv", nrows = 100, na.strings = "?")
df_src <- read.csv("sledzie.csv",
                   nrows = 60000, na.strings = "?",
                   colClasses = sapply(df_sample, class)) %>% 
  rename(row_id = X, month = xmonth) %>% relocate(month)
rm(df_sample)
tibble(df_src)
```

Loaded `r nrow(df_src)` rows with `r ncol(df_src)` columns from source.

## NA values in each column

```{r NA_in_each}
df_src %>% 
  summarise(across(everything(), function(x) sum(is.na(x)))) %>% 
  mutate(Total = sum(.)) %>% 
  kable()
```

## Distinct values in each column

```{r dist_in_each}
df_src %>% 
  summarise(across(everything(), n_distinct)) %>% 
  kable()
```

## Test grouping years by totaln

```{r test_group}
  df_src %>%
  group_by(totaln, month) %>%
  summarise(across(everything(), n_distinct), .groups = "drop") %>%
  summarise(across(everything(), function(x) sprintf("[%g-%g]", min(x), max(x)))) %>% 
bind_rows(.,
  df_src %>%
  na.omit() %>% 
  group_by(totaln, month) %>%
  summarise(across(everything(), n_distinct), .groups = "drop") %>%
  summarise(across(everything(), function(x) sprintf("[%g-%g]", min(x), max(x))))
) %>% 
bind_rows(.,
  df_src %>%
  group_by(totaln, month) %>%
  summarise(across(everything(), function(x) sum(is.na(x))), .groups = "drop") %>%
  summarise(across(everything(), function(x) sprintf("[%g-%g]", min(x), max(x))))
) %>% 
bind_rows(.,
  df_src %>%
  group_by(totaln, month) %>%
  summarise(across(everything(), function(x) length(x)-sum(is.na(x))), .groups = "drop") %>%
  summarise(across(everything(), function(x) sprintf("[%g-%g]", min(x), max(x))))
) %>% 
  select(-totaln, -month) %>% 
bind_cols(
  "across each distinct month" = c(
    "distinct values",
    "-//- no NA rows",
    "NA values",
    "not NA values"),.
) %>% 
  kable()
```

# Processing

Based on the data assumed that

* years result from unique values of totaln
  (equivalent to `fbar`, `recr`, `cumf`, due to only one distinct value for each group)
* following years derieved from average row id

```{r retrieve_time}
df_src %>%
  group_by(totaln) %>%
  summarise(across(everything(), mean, na.rm=TRUE), .groups = "drop") %>%
  arrange(row_id) %>% 
  mutate(year = row_number()) %>% 
  select(year, new.totaln = totaln) %>% 
  left_join(df_src, ., by = c("totaln" = "new.totaln")) %>% 
#  mutate(time = sprintf("%02d-%02d",year,month)) %>% 
  mutate(time = year+(month-1)/12) %>% 
  relocate(time, year) %>% 
  do(.,.) -> df_wTime
```

```{r make_months}
df_wTime %>% 
  group_by(time) %>%
  summarise(across(everything(), mean, na.rm=TRUE), n_rows = n(), .groups = "drop") %>% 
  do(.,.) -> df_grouped
```

## Data distribution

```{r Distributions}
df_grouped %>% 
  select(-c(time, year, month, row_id)) %>% 
  stack() %>% 
  ggplot(aes(y=values)) +
    geom_boxplot() +
    facet_wrap(~ind, scales = "free_y", ncol = 8) + 
    scale_x_continuous(breaks = NULL)
```

## Correlation {.tabset .tabset-fade .tabset-pills}

### Pearson

```{r cor_pearson}
df_grouped %>% 
  as.data.frame() %>% 
  cor(method = "pearson") %>% 
  corrplot(method ="circle")
```

### Kendall

```{r cor_kendall}
df_grouped %>% 
  as.data.frame() %>% 
  cor(method = "kendall") %>% 
  corrplot(method ="circle")
```

### Spearman

```{r cor_spearman}
df_grouped %>% 
  as.data.frame() %>% 
  cor(method = "spearman") %>% 
  corrplot(method ="circle")
```

## {.unlisted .unnumbered}
Visible correlation groups and 

* `fbar`, `recr`,`cumf`, `totaln`
* `length` and time measures
* `sst`, `length`
* `cfin1`, `cfin2`
* `chel1`, `chel2`,`clop1`, `clop2`
* `nao` with different measures (`chel1`, `clop1`, `sst`)

## Herring length over years {.tabset .tabset-fade .tabset-pills}

### All observations

```{r animate_time}
df_grouped %>% 
  mutate(trend_line = 
           predict(loess(length~time,.))) %>% 
  ggplot(aes(x=time, y=length)) +
    geom_point(aes(group = seq_along(time))) + 
    geom_line(aes(y=trend_line), linewidth=2, color="orange") +
    transition_reveal(time)
```

### All vs. >50

Number of records influence on results

```{r compare_nrow}
df_grouped %>%
  mutate(over50 = (n_rows > 50)) %>%
  ggplot(aes(x=time, y=length, color = over50)) + 
    geom_point() +
    labs(color = "More than 50")
```

# Regression model

```{r set_train}
df_grouped %>% 
#  group_by(-n_rows) %>% 
#  expand(n_rows = seq(1:n_rows)) %>% 
#  mutate(n_rows = max(n_rows)) %>% 
#  ungroup() %>% 
  do(.,.) -> df_pred
```

```{r reg_param}
trainIdx <- 
    createDataPartition(
        y = df_pred$length,
        p = .75,
        list = FALSE)

training <- df_pred[ trainIdx,]
testing  <- df_pred[-trainIdx,]

ctrl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 10)
```

## Predicted model

```{r train_reg}

fit <- train(length ~ .,
             data = training,
             method = "glm",
             trControl = ctrl,
             preProcess = c('scale', 'center'))
fit
```

## Variables importance

Importance of each variable in predicted model

```{r plt_imp}
ggplot(varImp(fit))
```

Most significant measures are:

* `cumf`
* `fbar`
* `sst`
* `totaln`

Their distribution over time:

```{r dist_over_time}
df_grouped %>% 
  pivot_longer(c(length,cumf, fbar, sst,totaln),
               names_to = "measure", values_to = "value") %>% 
  ggplot(aes(y=value, x=time)) +
    facet_grid(measure ~ ., scales = "free") +
    geom_point() + 
    geom_smooth() +
    ylab("")
```

## Prediction measures on testing set

```{r pred_meas}

postResample(pred = predict(fit, newdata = testing),
             obs = testing$length)
```

## Predicted model

```{r plt_pred}
df_grouped %>% 
  mutate(trend_line = 
           predict(loess(length~time,.))) %>% 
  mutate(pred = predict(fit, newdata = df_pred)) %>% 
  ggplot(aes(x=time, y=length)) +
    geom_point() +
    geom_line(aes(y = pred), linewidth=1, color="blue")
```



